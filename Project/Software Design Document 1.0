Project/Software Design Document 1.0
ERAU Graph-Theory Project
1. Project Overview
This project aims to create a graph-based materials database and accompanying AI models that:
Represent molecular structures as graphs (nodes as atoms, edges as bonds).
Predict how materials evolve over time (e.g., graphite to graphene).
Discover hidden correlations across diverse materials (metal behaving like rubber, etc.).
Provide a user-facing query interface that delivers high-quality, application-specific recommendations.
2. Goals and Objectives
Database Construction


Use Neo4j to store molecular and material data in a graph-based database 
Attached metadata for bond strength and properties (Also processing methods, historical data, etc. as a stretch goal)


AI Model Development


Evolution of Materials Model (Phase 2A): Predict how simpler materials transform into more advanced counterparts.
Hidden Connections Model (Phase 2B): Identify unexpected relationships and correlations in materials.


User Query Interface


A natural language question-and-answer system that retrieves and reasons over the materials database.

3. System Requirements
Data Ingestion & Integration


Pull data from Ansys Granta and other sources (PubChem, Materials Project) using APIs or CSV exports.
Regularly scheduled ETL processes for up-to-date info.


Graph Database


Store molecular structures, bonding information, and relevant material properties.
Must handle node/edge indexing and advanced graph queries.


Machine Learning Infrastructure


Must support training of Graph Neural Networks (GNNs), sequence models, and correlation-finding models.
Integration with experiment tracking (MLflow) and version control.


User Interface


Intuitive UI for domain experts and non-experts to query and get recommendations.
Natural language processing for ease of data exploration.

4. High-Level Architecture
        

5. Implementation Plan
Phase 1: Database and Training Data Creation
Data Ingestion and Cleaning


Tools: Python (Pandas), RDKit for molecular descriptor calculation.
Process:
Ingest from Ansys Granta (properties, chemical composition).
Use scripts to parse, clean, and standardize data (SMILES, InChI, etc.).


Graph Construction


Tools: RDKit to extract bonding info, Neo4j for storage.
Process:
Convert each molecule to a graph representation.
Store node (atom) attributes (atomic number, electronegativity) and edge (bond) attributes (single/double/triple).
Associate each graph with material property metadata.


ETL Pipeline Setup


Tools: Apache Airflow or Prefect.
Process:
Automate regular data imports/updates.
Validate data integrity and track changes over time.
Phase 2: Model Development
Core GNN for Property Prediction


Tools: PyTorch Geometric / TensorFlow GNN.
Process:
Train baseline GCN, GAT, or GraphSAGE models on the newly created dataset.
Evaluate performance with standard metrics (RMSE, MAE, etc.).


Model Versioning and Experiment Tracking


Tools: MLflow.
Process:
Track hyperparameters, datasets, and outcomes.
Store best-performing models for production inference.
Phase 2A: Evolution of Materials Model
Data Preparation for Evolution


Tools: Matminer or custom scripts.
Process:
Gather time-series or historical data of how certain materials changed (e.g., processing steps from graphite to graphene).
Represent “state transitions” in the graph database.


Model Development


Tools: Sequence-to-sequence Transformers (PyTorch).
Process:
Model evolves a base material (input) to a target advanced material (output).
Incorporate domain knowledge (pressure, temperature processes) as additional features.


Complex Material Evolution


Tools: Temporal Graph Networks or extended Transformer architecture.
Process:
Handle multi-step transitions for composites (e.g., from “low-tier carbon composites” to “high-performance CFRP”).
Validate predictions against known advancements in materials science.
Phase 2B: Hidden Connections Materials Model
Correlation & Pattern Mining


Tools: Autoencoders, Contrastive Learning, or Graph Attention Networks.
Process:
Identify latent spaces where unexpected similarities (e.g., metal vs. rubber) are revealed.
Use unsupervised methods to cluster or link materials based on functional behavior.


Cross-Validation


Tools: Clustering metrics (e.g., Silhouette Score).
Process:
Validate whether discovered connections align with known phenomena or highlight new research directions.
Phase 3: Query Interface / Recommendation Engine
NLP-Based Query System


Tools: GPT-style LLMs (OpenAI API or local large language model).
Process:
Fine-tune on domain-specific text and knowledge base.
Convert user queries to Cypher queries on Neo4j.
Return processed, user-friendly results with context.


Recommendation Engine


Tools: Knowledge Graph-based recommendation or collaborative filtering.
Process:
Suggest materials or potential evolutions to meet user criteria (strength, cost, process constraints).
Incorporate feedback loops to refine recommendations.
6. Timeline & Milestones
Month 1–4: Phase 1 Completion
Database schema finalized, ETL pipeline operational, initial data loaded.
Month 1–5: Phase 2 (Core GNN Model)
Baseline property-prediction model trained and validated.
Month 1–4: Phase 2A (Material Evolution)
Prototype evolution model for simpler materials completed and tested.
Month 5–8: Phase 2A (Complex Material Evolution)
Evolution model extended to handle multi-component materials.
Month 1–4: Phase 2B (Hidden Connections)
Hidden correlation model trained, results validated.
Month 5–6: Phase 3 (User Interface)
NLP-based query system and recommendation engine deployed.
7. Next Steps
Expand the dataset with more specialized materials (e.g., biopolymers).
Integrate real-time updates from lab experiments for model retraining.
Explore advanced neural architectures (graph transformers, hypergraph networks) for improved performance.
